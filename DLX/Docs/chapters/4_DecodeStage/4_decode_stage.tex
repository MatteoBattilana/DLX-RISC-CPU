\chapter{Decode Stage}
\label{sec:decode_stage}

The Decode Stage is the first DataPath stage, and logically, it's divided between the DataPath itself and a separated unit called ``Decode". The Decode Stage is mainly used to perform the Instruction Decode so identification of instruction type given its \emph{OP\_CODE} and then the dispatch of the operands contained in the instruction towards the DataPath. Meanwhile, other side operations, like computation of the new PC (given a jump or not), data hazard detection and comparisons, are performed.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.95\textwidth]{chapters/4_DecodeStage/images/Decode_stage_focus.pdf}
  \caption{Simplified schematic of the decode}
  \label{decode_block_focus}
\end{figure}

\section{Instruction Decode}

The most important operation is the Instruction Decode. Here, after the identification of the instruction type, its fields are extracted according to the general instruction structure, as described in Figure \ref{fig:rtype}, Figure \ref{fig:itype} and Figure \ref{fig:jtype}.\\

The Decode is based on the logic shown in Table \ref{table:decode_instr}. The table describes only the signals that go towards the DataPath and not the internal ones.

\begin{table}[H]
    \centering
    \begin{tabularx}{\textwidth}{|l|l|l|l|l|l|X|}
        \hline
        \textbf{Instruction} & INP1 & INP2 & RS1 & RS2 & WS & Note\\
        \hline
        RTYPE & \texttt{0} & \texttt{0} & \texttt{IR[25:21]} & \texttt{IR[20:16]} & \texttt{IR[15:11]} & \\
        \hline
        J & \texttt{0} & \texttt{0} & \texttt{R0} & \texttt{R0} & \texttt{R0} & \\
        \hline
        JAL (CALL) & \texttt{0} & \texttt{PC} & \texttt{R0} & \texttt{R0} & \texttt{R31} & \\
        \hline
        JALR & \texttt{0} & \texttt{PC} & \texttt{IR[25:21]} & \texttt{R0} & \texttt{R31} & \\
        \hline
        TICKTMR & \texttt{0} & \texttt{\emph{i\_TICKTMR}} & \texttt{R0} & \texttt{R0} & \texttt{IR[25:21]} & Destination reg on [25:21]\\
        \hline
        ITYPE & \texttt{0} & \texttt{IR[15:0]} & \texttt{IR[25:21]} & \texttt{IR[20:16]} & \texttt{IR[20:16]} & INP2 Sign Extension iff \emph{UNSIGNED\_ID}\\
        \hline
        LHI & \texttt{IR[15:0]} & \texttt{16} & \texttt{IR[25:21]} & \texttt{IR[20:16]} & \texttt{IR[20:16]} & No Sign Ext\\
        \hline
    \end{tabularx}
    \caption{Instruction Decoding}
    \label{table:decode_instr}
\end{table}

For Jump or Branch instruction, the immediate field doesn't go beyond the decode stage itself. The immediate is a relative value to be summed to the actual PC in case of a taken jump. For Jump-like instructions (J, JAL, CALL) the field is 26 bits long (far jumps), while for other branch instructions the field is 16 bits long (near jumps). In both cases, the value is extended to 32 bit with its sign because the relative value can be both positive (forward jumps) and negative (backward jumps).

\section{Register File and Windowing}
The general structure of a register file is based on a decoder that takes the selection input (so the address of the desired register) and enables it (also using the enable signal). An input signal will contain the value to be written. On the other hand, a read signal is used to select among all the registers.\newline\newline

The DLX presented in this document has been enhanced in order to be able to manage subroutine transparently from the point of view of the user. For this reason, the DLX must be able to handle subroutines, so the context switching, which consists of saving the content of the
registers to be restored once the procedure has been completed. The straightforward solution is to save into the memory all registers, but this is not feasible in terms of delay since, for 32 registers, 32 clock cycles are needed. In a pipeline, this corresponds to a long stall each time a procedure is called.\\

A windowed register allows reducing the overhead due to the context switch. The basic idea is to split the available registers in the physical register file into blocks, called \textit{windows}. There are a limited amount of physical registers in the register file; for this reason, a finite number of windows are defined. Each window is assigned to a subroutine so that the procedure can write only on those registers. This is transparent from the point of view of the CPU, which sees all registers available. Thus, the physical register file has a wrapper around it with a logic and a Register Management Logic (MML) that allows performing a translation between the CPU requests and the corresponding window for the running procedure.\newline\newline

When the number of called procedures is larger than the number of available windows, the main memory is involved, and the oldest allocated window is swapped in. This happens only when there are no free windows in the register file so that the new one can be allocated. Once all the recursion chain has been unrolled, the swapped windows in the memory must be restored into the register file.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{chapters/4_DecodeStage/images/DLX_RF.pdf}
    \caption{Schematic of the Windowing Register File}
    \label{WRF}
\end{figure}

All windows, so each procedure, is made of 4 blocks of 8 registers each one:
\begin{enumerate}
	\itemsep0sp
	\item \textbf{IN}: the first block is dedicated to the data inherited from the parent routine (previous OUT);
	\item \textbf{LOCAL}: contains the registers that are dedicated only to the procedure;
	\item \textbf{OUT}: is dedicated to the variables to be passed to the child routine, that is the IN of the next sub-procedure
	\item \textbf{GLOBAL}: the last block is common to every window.
\end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.65\textwidth]{chapters/4_DecodeStage/images/DLX_RF_BASICS.pdf}
    \caption{Logical organization of the Windowing Register File}
    \label{logical_wrf}
\end{figure}

When a procedure is called, the first LOCALS and OUT blocks are allocated from the physical file register and assigned to it (because IN is the OUT of the previous one).\\

By calling many nested procedures, at some point, there will be no free windows; for this reason, the oldest is de-allocated from the physical FR and swapped to the main memory. This operation is called \textbf{SPILL}. This is accomplished by using a support pointer, called \textbf{Saved Window Pointer SWP} that stores the pointer of the spilled data, exactly the end of the LOCALS block (only IN and LOCAL are spilled, the OUT block is not spilled because it is the IN of the next sub-procedure). In practice, it defines the position of the last free cell. Notice that this operation cannot be executed in one clock cycle: each register is spilled once at a clock cycle.\newline\newline

On the other hand, when the last procedure in the chain is finished, the others are unrolled; if some of them have been spilled, a \textbf{FILL} must be executed before the actual execution.\newline\newline

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{chapters/4_DecodeStage/images/DLX_RF_CWP_SWP.pdf}
    \caption{Logical Flow of CWP and SWP}
    \label{cwp_swp}
\end{figure}

It's important to notice that the implementation of the entire register file has been executed in a complete structural way. It is composed of several components:
\begin{itemize}
	\item \textbf{Decoder}: it is used to generate a single enable signal from an address on \emph{NBIT\_ADD} bits given by the CPU; in this way, a register is selected to perform a write. 
	\item \textbf{Connection matrix}: this component allows to ``highlight" the active windows, the block IN, LOCAL and OUT will be the default destination when writing and reading;
	\item \textbf{Register file}: this block corresponds to the physical registers, composed by rows of registers;
	\item \textbf{Select block}: this block is used for reading: it is connected to all the registers and selects, using the window pointer, all the registers that belong to the pointed window. A multiplexer then is used to read from a single register;
	\item \textbf{Address generator}: this block is only used when performing a FILL or a SPILL. It generates the address for the registers to be moved from/to the memory. The latter, in this situation, works exactly like a stack;
	\item \textbf{WRF Control Unit}: A FSM is used to manage and generate the memory addresses when performing a SPILL or a FILL.
\end{itemize}

Additional but less complex hardware has been used in order to manage the CWP and SWP. The complete diagram is available at Figure \ref{figure:wrf_complex}.


\subsection{Decoder}
This block receives as input the \emph{write address} on \emph{NBIT\_ADD} bits and outputs \(\mathbf{2^{NBIT\_ADD} - 1} \) bits. It has the utility of converting the address of the register at which the CPU needs to write into the relative register enable signal. 

The idea is that if the input is \(0b00010\) the output has to be \(0b00000000000000000000000000000100\). If the input is decimal 2, it means that the CPU needs to write the second register of the \emph{GLOBAL} block. In terms of enable signals, it translates into having the bit with index 2 at one. \\

The output is divided, as shown in Figure \ref{decoder}, in order to represent the group of bits. In particular: 

\begin{center}
	DECODED ADDRESS: \emph{0b} $\underbrace{00000100}_{\text{OUT}}$ $\underbrace{00000100}_{\text{LOCAL}}$ $\underbrace{00000100}_{\text{IN}}$ $\underbrace{00000100}_{\text{GLOBAL}}$
\end{center}

On the top of the schematic \autoref{decoder} an AND logic gate between an \emph{ENABLE} signal and the \emph{WR} signal is used. If both \emph{ENABLE} and \emph{WR} are at 1, it means that the register is enabled.\\

The generated enable signal is called \emph{Logical Enable Signal}. To generate the \emph{Physical Enable Signal}, a translation is needed and it's performed by the \emph{connection matrix}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{chapters/4_DecodeStage/images/Decoder.pdf}
    \caption{Schematic of the Decoder}
    \label{decoder}
\end{figure}

\subsection{Connection Matrix}

With the previous block, all the logical enable signals are generated. They are related to a single window, so a block that puts together the required enabled register and the actual window is needed. 

This block receives as inputs the signals coming from the decoder and the current window. The output is an enable signal that is a translation from the ``logic" enable (the one referred to a virtual register, the ones that are seen by the CPU) and the physical one (within the actual window). This is related to the logic placed on the left in Figure \ref{connection_matrix}.\\

There is a specific structure for each group of logical enable signals:
\begin{itemize}
  \item GLOBAL ones: the global is the simplest because it is always the same despite the selected window.
  \item IN: for this group of registers, one of them is activated when ``an IN enable signal is high AND the related window is active OR an OUT enable signal is high AND the previous related window is active".
  \item OUT: same reason as before: ``an OUT enable signal is high AND the related window is active OR an IN enable signal is active and the next related window is active".
  \item LOCAL: for this block, a simple AND is used with the LOCAL enable coming from the decoder and the related window. 
\end{itemize}

However, the connection matrix is used during a FILL operation too. It addresses the group of registers to be restored. For this purpose, it receives the SWP and FILL signal and the same reasoning is applied (group of logic in the middle in Figure \ref{connection_matrix}).

For addressing during the FILL operation, an internal address signal is used, called addr\_pop. This group of signals is generated by an address\_generator unit that produces the addresses from the last to the first one. This happens because the memory is used like a STACK.\\

\begin{figure}[H]
  \centering
  \includegraphics[width=0.9\textwidth]{chapters/4_DecodeStage/images/connection_matrix.pdf}
  \caption{Connection matrix}
  \label{connection_matrix}
\end{figure}

\subsection{Physical Register File}

The next block is the Physical Register File, which is a sequence of registers. For writing operations, there are two sources of Data: the ones coming from the CPU that wants to write in a register and the ones coming from the memory during a FILL operation. In order to support this kind of access, a multiplexer is used for each window, so for each group of IN-LOCAL.\\

The multiplexer selection signal is the $SWP-1$ because the SWP always points to the window that eventually needs to be spilled so the previous one is the one that has been spilled and so it's the right one to restore.

\subsection{Select Block}

The purpose of this unit is very simple and straightforward. It receives as input the current window and the output of all the registers, and it outputs the content of the IN, LOCAL and OUT of the current window. Its interface is shown in \autoref{select_block}.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.9\textwidth]{chapters/4_DecodeStage/images/select_block.pdf}
  \caption{Interface of the select block}
  \label{select_block}
\end{figure}

\subsection{Output Selection Stage}
This is the stage that decides the outputs RD1 and RD2 of the Register File. The design is shown in \autoref{output_choice}.\\

This stage receives the IN, LOCAL, OUT of the current window, thanks to the select block, and the GLOBAL. The two addresses, ADD\_RS1 and ADD\_RS2, select the single register output through the multiplexer.\\

A latch is placed between the multiplexer output and the final output of the register file. When one of the two read port is disabled, the latch is in memory state so the output will remain stable.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{chapters/4_DecodeStage/images/output_choice.pdf}
  \caption{Design of the output selection}
  \label{output_choice}
\end{figure}


\subsection{Next Window Calculator}

This block is used to compute the next window, both for the current window and the saved window. The schematic is shown in \autoref{nwin_cal}.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\textwidth]{chapters/4_DecodeStage/images/nwin_cal.pdf}
  \caption{Design of the next window calculator}
  \label{nwin_cal}
\end{figure}

Inside this block there is a logic able to rotate right or left and a multiplexer that allows selecting the correct output based on what the circuit needs. 

\subsection{WRF Control Unit}

An additional element is necessary in order to be able to manage the addresses for the SPILL and FILL procedure to and from memory. It has been implemented using a Moore FSM and consists of different phases; a starting one that set the memory address to 0 and when the FILL or SPILL input is `1' and the ram is ready, the address is decreased or increased by 4, accordingly to the operation. Refer to figure \ref{wrf_cu}. It's important to say that, if the RAM is not ready the address is kept untouched, so that when the RAM returns in a ready state, the procedure can continue.


\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\textwidth]{chapters/4_DecodeStage/images/wRF_CU.pdf}
	\caption{Moore FSM implementation for WRF CU}
	\label{wrf_cu}
\end{figure}

\section{Hazard Control}

During the execution of a pipeline, different problems or hazard situations may occur. Regarding Data Hazards, the most dangerous situation is the \emph{Read After Write (RAW)}. So a solution is needed in order to detect these problems and actually, there exist a unit inside the Decode Stage that is dedicated to this job, the \emph{Hazard Table}.\\

RAW Hazards occurs when an instruction wants to read from a register that is the destination register of a previous instruction still inside the pipeline so and not completed. This means that the second instruction has to be stopped (i.e. a stall or a bubble must be inserted into the pipeline) until the previous instruction has been completed.\\

\begin{lstlisting}[style=mips,nolol, caption={Example of DLX ASM code for RAW Hazard},label=raw_hazard]
	add r1, r2, r3
	add r4, r1, r2 # RAW HAZARD
\end{lstlisting}

The \emph{Hazard Table} is made of a table with 32 entries (one for each register of the DLX). Each entry is made of 3 bits. When an instruction exits the Decode Stage and enters the Execute Stage, the related destination address entry in the table is increased by one. When the instruction reaches the Write Back Stage, the corresponding entry is decreased by one.\\

When a new instruction is decoded, its source registers are checked inside the \emph{Hazard Table}: if one or both the registers have an entry greater than 0 means that one of them is not available (i.e. a previous instruction is still writing on that register) and the Decode Stage raises a \emph{Hazard Signal} towards the Control Unit that will insert stalls inside the pipeline until the hazard is solved. When the hazard is over, the instruction will be processed inside the pipeline.

\section{Comparator}
\label{sec:comparator}
The straightforward way to implement a comparator, allows only to check if two operands, \texttt{A} and \texttt{B}, are equals. The solution is sketched at figure \ref{fig:comparator_basic}, which is based on $N$ XNOR, where $N$ is the number of bits of the operands and an AND gate with $N$ inputs.

Even if this solution is extremely compact, it allows to perform only the equality comparison; since this DLX implementation has the ability to perform complex conditional branch instructions (refer to the Instruction section \ref{section:inst_set}) and conditional set instructions (refer to the Set-Like Operations Unit \ref{sec:set_like}) a more complex solution is requested. For example, if a conditional branch based on the condition \texttt{A} $>$ \texttt{B} (strictly greater) is executed, the exact check of this precise condition has to be performed.

\begin{figure}[H]
	\centering
	\begin{minipage}{.5\textwidth}
		\centering
		\includegraphics[width=0.55\textwidth]{chapters/4_DecodeStage/images/comparator_basic.pdf}
		\caption{Design of the basic comparator}
		\label{fig:comparator_basic}
	\end{minipage}%
	\begin{minipage}{.5\textwidth}
		\centering
		\includegraphics[width=0.7\textwidth]{chapters/4_DecodeStage/images/comparator_advanced.pdf}
		\caption{Design of the advanced comparator}
		\label{comparator_advanced}
	\end{minipage}
\end{figure}

The advance comparator exploits the comparison by performing a subtraction between \texttt{A} and \texttt{B} and then checking the result. This DLX implementation is based on a P4 adder that is able to perform subtraction and then a set of checks, the same that are in the \ref{comparator_advanced} are performed in order to generate the comparison outputs. The comparisons can be performed using the following boolean equations, where $C$ is the carry-out and $Z$ is the zero check (all bits of the results are zeros):
\begin{align*}
	A > B &\rightarrow C \cdot \overline{Z}\\
	A \geq B &\rightarrow C\\
	A < B  &\rightarrow \overline{C}\\
	A \leq B &\rightarrow \overline{C} + Z\\
	A = B &\rightarrow Z\\
	A \neq B  &\rightarrow \overline{Z} 
\end{align*}

 In order to avoid to propagate six different signal, the outcomes of the comparisons are encoded into a signal \texttt{LGET} on two bits. The encoded value are the ones in the Table \ref{tab:lget}.
 \begin{multicols}{2}
 	\begin{table}[H]
 		\begin{center}
 			\begin{tabular}{ c| c}
 				\texttt{LGET} & Case\\
 				\hline
 				01 & $A < B$ \\
 				00 & $A \leq B$ \\
 				11 & $A > B$ \\
 				10 & $A \geq B$
 				
 			\end{tabular}
 			\caption{LGET encoding}
 			\label{tab:lget}
 		\end{center}
 	\end{table}
 	
 	\columnbreak
 	
 	\begin{lstlisting}[style=vhdl,caption={VHDL code for the encodig},label=lget_code]
 	LGET <= "01" when (a_l_b = '1') else
	 	"00" when (a_le_b = '1') else 
	 	"11" when (a_g_b = '1') else
	 	"10" when (a_ge_b = '1') else
	 	"00";
 	\end{lstlisting}
 \end{multicols}

 The ordering of the comparison in the \texttt{when} statement is not casual nor follows the normal patterns. The strictly lower comparison is made before the lower equals one, because, if the latter one is true, it means that also \texttt{A} lower than \texttt{B} is true, but not vice-versa. Using this encoding, the CPU can check the second bit in order to understand if \texttt{A} $\leq$ \texttt{B} or \texttt{A} $\geq$ \texttt{B}; instead, if the CPU wants to check only $<$ or $>$ comparisons the CPU has to check also the first bit.

 

A further improvement has been done to the advanced comparator in order to manage comparison between both signed and unsigned numbers. The carry value works like this:
\begin{itemize}
  \item Carry = 1: if \(A > B\) in unsigned
  \item Carry \(=\) 0: if \(A \leq B\) in unsigned
\end{itemize}

The advanced comparator works with unsigned numbers only. So it simply needs to be adapted for cases in which signed comparison and unsigned comparison are different. They are shown in the \autoref{comparator_cases} highlighted in red. 
It is easy to notice that in the red lines, A and B always have different signs. Therefore, the logic must work when the \texttt{UNSIG\_SIGN\_N} bit is 0, which means that the circuit is dealing with a signed number. In this case, the carry bit must be complemented. Knowing this, it's easy to derive the following logic:

\begin{center}
	$Cout\_masked \leftarrow Cout \oplus (\overline{UNSIG\_SIGN\_N} \cdot (A_{msb} \oplus B_{msb}))$
\end{center}
% \begin{verbatim}
%   i_cout_masked <= Cout xor (not(UNSIG_SIGN_N) and (A(A'length-1) xor B(B'length-1)));
% \end{verbatim}

\begin{table}[H]
  \centering
  \begin{tabular}{c|c|c|c|c}
      \textbf{A} & \textbf{B} & \textbf{Carry out} & \textbf{Signed comparison} & \textbf{Unsigned comparison} \\
      \hline
      2 & 3 & 0 & Less & Less \\
      4 & 3 & 1 & Greater & Greater \\
      3 & 3 & 1 & Equal & Equal \\
      \rowcolor{red!50}
      -3 & 3 & 1 & Less & Greater \\
      \rowcolor{red!50}
      -2 & 3 & 1 & Less & Greater \\
      \rowcolor{red!50}
      -5 & 3 & 1 & Greater & Greater \\
      \hline
      3 & 2 & 1 & Greater & Greater \\
      3 & 4 & 0 & Less & Less \\
      3 & 3 & 1 & Equal & Equal \\
      \rowcolor{red!50}
      3 & -3 & 0 & Greater & Less \\
      \rowcolor{red!50}
      3 & -2 & 0 & Greater & Less \\
      \rowcolor{red!50}
      3 & -5 & 0 & Greater & Less \\
      \hline
      \rowcolor{red!50}
      2 & -3 & 0 & Greater & Less \\
      \rowcolor{red!50}
      4 & -3 & 1 & Greater & Less \\
      \rowcolor{red!50}
      3 & -3 & 1 & Greater & Less \\
      -3 & -3 & 1 & Equal & Equal \\
      -2 & -3 & 1 & Greater & Greater \\
      -5 & -3 & 1 & Less & Less \\
      \hline
      \rowcolor{red!50}
      -3 & 2 & 1 & Less & Greater \\
      \rowcolor{red!50}
      -3 & 4 & 0 & Less & Greater \\
      \rowcolor{red!50}
      -3 & 3 & 1 & Less & Greater \\
      -3 & -3 & 0 & Equal & Equal \\
      -3 & -2 & 0 & Less & Less \\
      -3 & -5 & 0 & Greater & Greater \\
  \end{tabular}
  \caption{All cases of possible comparison}
  \label{comparator_cases}
\end{table}
So, the final unit corresponds to the one at figure \ref{comparator_advanced} with an additional encoder before the output that encodes the six conditions into a signal on two bits. The resulting schema is the one in figure \ref{cmp_final}. The comparator is used both in the decode stage for the branch instructions and to reduce the area and reuse the component in the Set-Compare Unit in the Execute Stage.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.3\textwidth]{chapters/4_DecodeStage/images/cmp_final.pdf}
	\caption{Final implementation of the comparator}
	\label{cmp_final}
\end{figure}

It is important to mention the utility of the multiplexer before the comparator in \autoref{decode_block}. There are two cases in which the comparator is used:

\begin{itemize}
  \item Comparison between the content of two registers: in this case the multiplexer will select, with a 1, \texttt{i\_RD2} and so the comparator will compare \texttt{i\_RD1} and \texttt{i\_RD2}. For example operations like BGT, BGE fall within this subcase. 
  \item Comparison between the content of a register and an immediate: in this case the multiplexer will select, with a 0, \texttt{i\_INP2} that is the immediate. So the comparator will compare \texttt{i\_RD1} and \texttt{i\_INP2}. For example, operations like SEQI, SNEI fall within this subcase. 
\end{itemize}

The selection signal of the multiplexer is hardcoded into the control word

\section{Jump and Branch decision}
When taking into consideration jump and branch decisions, there are many details to explain. First, as shown in \autoref{table:decode_instr}, there are some instructions, like JAL and JALR, that need to save the value of the current program counter inside the register R31. For this reason, the value of WS is set to R31 in this kind of instruction. 

Another important thing is that when jumping, there needs to be a change on the program counter. In order to exploit this feature, there is dedicated hardware inside the decode block that takes into account the computation of the next program counter. All the circuits and their functionalities are explained in the next section. 

In the control word, there is a dedicated bit for the \texttt{JUMP\_EN}. For the instructions that require a jump, such as J, JAL, JALR, CALL and RET, this bit is set to 1 by default. For other instructions that may jump, particularly the conditional branches, there is an intermediate step, the comparator. In fact, for these instructions, the \texttt{JUMP\_EN} bit is set to 0 by default. Then, thanks to a process inside the control unit, based on the opcode and on the signal \texttt{LGET}, the \texttt{JUMP\_EN} is set to 1 as well as \texttt{IF\_STALL}. This is very important because when jumping, there is a need to fetch the next instruction. For this reason, the first stage of the pipeline is stalled to avoid fetching the next instruction immediately. 

The content of the process that exploits the functionalities just explained is the following:
\newline

\begin{lstlisting}[style=vhdl,caption={VHDL code for the conditional branch},label=conditional_branches_code]
  if (IR_opcode = OP_BEQZ and LGET(0) = '0') then -- BEQZ 
    i_JUMP_EN <= '1';
    IF_STALL <= '1';
  elsif (IR_opcode = OP_BNEZ and LGET(0) = '1') then -- BNEZ
    i_JUMP_EN <= '1';
    IF_STALL <= '1';
  elsif (IR_opcode = OP_BGE and (LGET(1) = '1' or LGET(0) = '0')) then -- BGE
    i_JUMP_EN <= '1';
    IF_STALL <= '1';
  elsif (IR_opcode = OP_BLE and LGET(1) = '0') then -- BLE
    i_JUMP_EN <= '1';
    IF_STALL <= '1';
  elsif (IR_opcode = OP_BGT and LGET = "11") then -- BGT
    i_JUMP_EN <= '1';
    IF_STALL <= '1';
  elsif (IR_opcode = OP_BLT and LGET = "01") then -- BLT
    i_JUMP_EN <= '1';
    IF_STALL <= '1';
  elsif (IR_opcode = OP_CALL and BUSY_WINDOW = '1') then -- CALL
    CALL <= '0';
    i_JUMP_EN <= '0';	
  elsif (IR_opcode = OP_CALL and BUSY_WINDOW = '0' and i_SPILL_delay = '0') then -- CALL
    CALL <= '1';
  elsif (IR_opcode = OP_RET and BUSY_WINDOW = '1') then -- RET
    RET <= '0';
    i_JUMP_EN <= '0';
  end if;
\end{lstlisting}

To check if a branch must be taken or not:
\begin{itemize}
  \item BEQZ: if the LSB of \texttt{LGET} is 0, then it means that there is equivalence with 0
  \item BNEZ: if the LSB of \texttt{LGET} is 1, then it means that there is don't have equivalence with 0
  \item BGE: if the LSB of \texttt{LGET} is 0 or if the LSB+1 of \texttt{LGET} is 1
  \item BLE: if the LSB+1 of \texttt{LGET} is 0, then it means that there is less equal
  \item BGT: if LGET = 11
  \item BLT: if LGET = 01
\end{itemize}

The last cases to analyze are the ones in which there is CALL or RET. If there is \texttt{BUSY\_WINDOW} equal to 1, it means that the current window is still in use, and so no operation on it have to be executed. In fact \texttt{JUMP\_EN} is set to 0.

The last case is the one when \texttt{BUSY\_WINDOW} is 0 and so the execution of the CALL procedure is feasible. In fact, \texttt{CALL} is set to 1.

\section{Next Program Counter computation}
The next program counter computation is included inside the decode block to manage hazards and jumps better. In addition, to lighten the load on the ALU, a dedicated P4 adder has been included inside the decode block to compute the next program counter. 
The complete schematic of the decode is shown in \autoref{decode_block}.

\begin{figure}[H]
	\centering
  \addtolength{\leftskip}{-3cm}
  \addtolength{\rightskip}{-3cm}
	\includegraphics[width=1.2\textwidth]{chapters/4_DecodeStage/images/decode_block.pdf}
	\caption{Schematic of the decode block}
	\label{decode_block}
\end{figure}

There are 2 possible conditions:

\begin{enumerate}
  \item \texttt{JUMP\_EN = 0}: this means that there is no jump. So the program counter should be increased by a constant value, in our case 4. By comparing the explanation and the schematic, it's clear how the left multiplexer, with a 0, will select the signal \texttt{i\_CONSTANT\_PC\_ADD}. Then the two signals enter the P4 Adder and the next program counter is computed. The carry out of the P4 adder is mapped on a signal called \texttt{PC\_OVF}, used to report a program counter overflow. 
  \item \texttt{JUMP\_EN = 1}: this means that there is a jump. So the program counter should be increased by an offset. Looking at the schematic, it's clear how the left multiplexer, with a 1, will select the signal \texttt{i\_PC\_OFFSET}. Then the two signals enter the P4 Adder and the next program counter is computed. 
\end{enumerate}

The multiplexer on the right is controlled by a signal from the control unit, in particular from the control word. The only three instructions in which the value of \texttt{NPC\_SEL} is 1, and so it selects RD1, are:

\begin{itemize}
  \item JR
  \item JARL
  \item RET
\end{itemize}

In fact, in these cases, the absolute value of the program counter to be used it the one read from the register file, in particular from \texttt{RD1}.

\section{Tickcounter}
When thinking about improving the PRO version of the DLX further, the idea was to implement a counter. As it's known, counters are very common inside microprocessors because they are helpful to keep track of the timing. 
The implementation chosen in the DLX was straightforward. There is a half-adder on 32 bits that every rising edge of the clock increases the value of the register used inside the tickcounter block to keep track of the value. By doing this, the programmer can count the number of ticks and use the value to estimate the duration of a specific program. 
